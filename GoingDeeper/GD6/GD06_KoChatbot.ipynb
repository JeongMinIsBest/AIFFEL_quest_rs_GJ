{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.12/site-packages (0.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('ChatbotData.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(questions))\n",
    "    f.write('\\n'.join(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=all.txt --model_prefix=chatbot --vocab_size=8007 --model_type=bpe --max_sentence_length=999999 --pad_id=0 --pad_piece=[PAD] --unk_id=1 --unk_piece=[UNK] --bos_id=2 --bos_piece=[BOS] --eos_id=3 --eos_piece=[EOS] --user_defined_symbols=[SEP],[CLS],[MASK]\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: all.txt\n",
      "  input_format: \n",
      "  model_prefix: chatbot\n",
      "  model_type: BPE\n",
      "  vocab_size: 8007\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 999999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: [SEP]\n",
      "  user_defined_symbols: [CLS]\n",
      "  user_defined_symbols: [MASK]\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: [UNK]\n",
      "  bos_piece: [BOS]\n",
      "  eos_piece: [EOS]\n",
      "  pad_piece: [PAD]\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: all.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 23645 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [PAD]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [UNK]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [BOS]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [EOS]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [SEP]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [CLS]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [MASK]\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=369706\n",
      "trainer_interface.cc(552) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=1081\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 23645 sentences.\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 23645\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 20693\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13944 min_freq=42\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1055 size=20 all=16167 active=1765 piece=▁거예요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=776 size=40 all=16883 active=2481 piece=▁여\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=619 size=60 all=17546 active=3144 piece=▁좋아하는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=427 size=80 all=18152 active=3750 piece=▁모\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=358 size=100 all=18881 active=4479 piece=▁전\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=357 min_freq=37\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=307 size=120 all=19314 active=1399 piece=▁뭐\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=262 size=140 all=19907 active=1992 piece=▁소\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=227 size=160 all=20331 active=2416 piece=▁비\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=206 size=180 all=20687 active=2772 piece=▁행\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=188 size=200 all=21059 active=3144 piece=▁관\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=188 min_freq=31\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=172 size=220 all=21413 active=1400 piece=▁재\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=155 size=240 all=21741 active=1728 piece=▁데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=144 size=260 all=22062 active=2049 piece=▁자꾸\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=136 size=280 all=22443 active=2430 piece=▁고백\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=130 size=300 all=22796 active=2783 piece=▁먼저\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=130 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=122 size=320 all=23129 active=1469 piece=▁헤어진지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=115 size=340 all=23459 active=1799 piece=▁버\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=108 size=360 all=23675 active=2015 piece=▁돈\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=103 size=380 all=24001 active=2341 piece=▁곳\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=99 size=400 all=24397 active=2737 piece=▁함\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=99 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=92 size=420 all=24680 active=1501 piece=▁남자친구\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=87 size=440 all=24901 active=1722 piece=다가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=85 size=460 all=25157 active=1978 piece=▁사람은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=480 all=25444 active=2265 piece=▁내일\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=500 all=25674 active=2495 piece=리고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=77 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=75 size=520 all=25899 active=1487 piece=▁어떨까요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72 size=540 all=26127 active=1715 piece=▁해도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=560 all=26402 active=1990 piece=▁그만\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=580 all=26568 active=2156 piece=▁휴\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=600 all=26754 active=2342 piece=▁항상\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=64 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=620 all=26920 active=1504 piece=▁문제\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=640 all=27183 active=1767 piece=▁상황\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=660 all=27430 active=2014 piece=▁개\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=680 all=27636 active=2220 piece=▁가보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=700 all=27758 active=2342 piece=▁충분히\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=53 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=720 all=27910 active=1540 piece=▁열심히\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=740 all=28050 active=1680 piece=▁종\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=760 all=28206 active=1836 piece=▁부모\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=780 all=28339 active=1969 piece=으니까요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=800 all=28484 active=2114 piece=▁부모님\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=47 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=820 all=28589 active=1520 piece=▁헤어지고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=840 all=28721 active=1652 piece=더니\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=860 all=28862 active=1793 piece=▁살아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=880 all=28954 active=1885 piece=▁모르는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=900 all=29084 active=2015 piece=▁스스로\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=41 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=920 all=29222 active=1588 piece=▁정리가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=940 all=29333 active=1699 piece=▁끊\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=960 all=29525 active=1891 piece=▁잘하는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=980 all=29677 active=2043 piece=▁정도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=1000 all=29823 active=2189 piece=▁붙잡\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=36 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=1020 all=29947 active=1604 piece=같아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=1040 all=30075 active=1732 piece=기는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=1060 all=30222 active=1879 piece=드릴게요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=1080 all=30371 active=2028 piece=▁힘내세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=1100 all=30470 active=2127 piece=▁언젠간\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=32 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=1120 all=30569 active=1623 piece=▁받고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=1140 all=30660 active=1714 piece=▁나아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=1160 all=30760 active=1814 piece=어야\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=1180 all=30874 active=1928 piece=이었을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=1200 all=30996 active=2050 piece=▁꿈에\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=28 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=1220 all=31049 active=1602 piece=여보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=1240 all=31149 active=1702 piece=▁싸우\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1260 all=31170 active=1723 piece=▁냉\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1280 all=31266 active=1819 piece=▁어렵\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1300 all=31340 active=1893 piece=▁만났어\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=26 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1320 all=31440 active=1667 piece=아서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1340 all=31568 active=1795 piece=▁알고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1360 all=31627 active=1854 piece=▁힘들죠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=1380 all=31719 active=1946 piece=▁미치\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=1400 all=31793 active=2020 piece=▁알려줘\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=1420 all=31842 active=1637 piece=▁먹을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=1440 all=31961 active=1756 piece=▁드디어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1460 all=32021 active=1816 piece=▁경우\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1480 all=32072 active=1867 piece=▁차분\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1500 all=32136 active=1931 piece=▁거기까지\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1520 all=32276 active=1743 piece=▁10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1540 all=32342 active=1809 piece=답니다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1560 all=32381 active=1848 piece=▁자연스러운\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1580 all=32485 active=1952 piece=야할\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1600 all=32595 active=2062 piece=▁집중\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1620 all=32631 active=1659 piece=▁준비가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1640 all=32663 active=1691 piece=치가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1660 all=32770 active=1798 piece=▁오빠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1680 all=32856 active=1884 piece=▁받았어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1700 all=32865 active=1893 piece=▁걷\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1720 all=32993 active=1763 piece=이요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1740 all=33080 active=1850 piece=▁애랑\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1760 all=33136 active=1906 piece=▁아름���\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1780 all=33153 active=1923 piece=고생\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1800 all=33289 active=2059 piece=▁나타\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1820 all=33345 active=1717 piece=▁있고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1840 all=33397 active=1769 piece=▁한동안\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1860 all=33438 active=1810 piece=냐고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1880 all=33544 active=1916 piece=▁다니\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1900 all=33597 active=1969 piece=▁없애\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1920 all=33675 active=1752 piece=▁SNS\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1940 all=33692 active=1769 piece=▁사랑하는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1960 all=33746 active=1823 piece=소한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1980 all=33838 active=1915 piece=▁돈을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=2000 all=33909 active=1986 piece=▁일상\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=2020 all=33954 active=1735 piece=▁소중한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=2040 all=33961 active=1742 piece=▁않았어요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2060 all=33998 active=1779 piece=▁헛\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2080 all=34137 active=1918 piece=▁나의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2100 all=34177 active=1958 piece=▁잡고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2120 all=34203 active=1735 piece=▁벗어나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2140 all=34199 active=1731 piece=▁생각나네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2160 all=34187 active=1719 piece=▁이해해주세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2180 all=34254 active=1786 piece=먹고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2200 all=34387 active=1919 piece=▁나올\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2220 all=34427 active=1757 piece=▁샀어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2240 all=34497 active=1827 piece=▁인간\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2260 all=34571 active=1901 piece=▁결정을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2280 all=34575 active=1905 piece=▁없다고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2300 all=34591 active=1921 piece=▁후회가\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2320 all=34591 active=1730 piece=▁무시하세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2340 all=34638 active=1777 piece=되는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2360 all=34720 active=1859 piece=▁끝난\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2380 all=34754 active=1893 piece=▁소원\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2400 all=34784 active=1923 piece=▁취향\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2420 all=34823 active=1774 piece=▁됩니다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2440 all=34823 active=1774 piece=▁없어��\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2460 all=34807 active=1758 piece=▁상대방이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2480 all=34792 active=1743 piece=▁응원합니다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2500 all=34823 active=1774 piece=▁합\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2520 all=34915 active=1831 piece=전에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2540 all=34962 active=1878 piece=▁나면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2560 all=34986 active=1902 piece=▁불행\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2580 all=35034 active=1950 piece=▁외국\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2600 all=35088 active=2004 piece=만으로\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2620 all=35122 active=1783 piece=▁마무리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2640 all=35123 active=1784 piece=▁있다고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2660 all=35131 active=1792 piece=▁사랑으로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2680 all=35119 active=1780 piece=▁힘들겠네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2700 all=35152 active=1813 piece=갈까\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2720 all=35235 active=1835 piece=이니\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2740 all=35292 active=1892 piece=▁내요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2760 all=35327 active=1927 piece=▁변명\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2780 all=35368 active=1968 piece=▁이뤄\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2800 all=35414 active=2014 piece=이라고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2820 all=35455 active=1806 piece=▁됐는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2840 all=35452 active=1803 piece=▁아프다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2860 all=35442 active=1793 piece=▁태어난\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2880 all=35451 active=1802 piece=▁생각하면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2900 all=35441 active=1792 piece=▁다르겠지만\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2920 all=35466 active=1798 piece=▁닮\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2940 all=35534 active=1866 piece=라이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2960 all=35654 active=1986 piece=하대\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2980 all=35690 active=2022 piece=▁대출\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3000 all=35716 active=2048 piece=▁살기\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3020 all=35735 active=1804 piece=▁왔네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3040 all=35768 active=1837 piece=▁회식\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3060 all=35845 active=1914 piece=▁가는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3080 all=35844 active=1913 piece=▁되는지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3100 all=35833 active=1902 piece=▁알아차\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3120 all=35828 active=1784 piece=▁재미가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3140 all=35821 active=1777 piece=▁기다리면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3160 all=35817 active=1773 piece=▁있었으면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3180 all=35810 active=1766 piece=▁감사합니다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3200 all=35790 active=1746 piece=..\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3220 all=35825 active=1823 piece=걸로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3240 all=35892 active=1890 piece=이스\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3260 all=35943 active=1941 piece=▁기간\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3280 all=35965 active=1963 piece=▁매너\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3300 all=36004 active=2002 piece=▁새해\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3320 all=36042 active=1836 piece=▁여우\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3340 all=36068 active=1862 piece=▁주기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3360 all=36100 active=1894 piece=▁해봤\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3380 all=36171 active=1965 piece=이세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3400 all=36192 active=1986 piece=▁나만의\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3420 all=36187 active=1805 piece=▁만나도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3440 all=36178 active=1796 piece=▁세상은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3460 all=36169 active=1787 piece=▁위해서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3480 all=36164 active=1782 piece=▁후회는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3500 all=36176 active=1794 piece=▁드릴게요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3520 all=36169 active=1802 piece=▁좋아하나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3540 all=36158 active=1791 piece=▁사랑이네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3560 all=36144 active=1777 piece=▁끓\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3580 all=36185 active=1818 piece=▁흥\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3600 all=36243 active=1876 piece=료가\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3620 all=36318 active=1887 piece=장에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3640 all=36348 active=1917 piece=▁거요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3660 all=36362 active=1931 piece=▁너는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3680 all=36380 active=1949 piece=▁못했\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3700 all=36401 active=1970 piece=▁신기\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3720 all=36417 active=1833 piece=▁입지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3740 all=36430 active=1846 piece=▁축복\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3760 all=36476 active=1892 piece=에서도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3780 all=36517 active=1933 piece=▁계획을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3800 all=36501 active=1917 piece=▁될지도\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3820 all=36499 active=1824 piece=▁번호를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3840 all=36489 active=1814 piece=▁아니고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3860 all=36483 active=1808 piece=▁운명이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3880 all=36484 active=1809 piece=▁처음에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3900 all=36479 active=1804 piece=하니까요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3920 all=36470 active=1811 piece=▁사랑에는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3940 all=36458 active=1799 piece=▁있었나요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3960 all=36453 active=1794 piece=▁힘들지요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3980 all=36436 active=1777 piece=▁억지로라도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4000 all=36426 active=1767 piece=▁곱\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4020 all=36450 active=1843 piece=▁찼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4040 all=36508 active=1901 piece=도는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4060 all=36568 active=1961 piece=와서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4080 all=36617 active=2010 piece=표현\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4100 all=36655 active=2048 piece=▁갖지\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4120 all=36672 active=1850 piece=▁놀다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4140 all=36698 active=1876 piece=▁많네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4160 all=36710 active=1888 piece=▁분노\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4180 all=36719 active=1897 piece=▁슈퍼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4200 all=36739 active=1917 piece=▁어둠\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4220 all=36756 active=1852 piece=▁이뻐\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4240 all=36762 active=1858 piece=▁좋고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4260 all=36794 active=1890 piece=▁치유\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4280 all=36809 active=1905 piece=▁형편\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4300 all=36849 active=1945 piece=스피싱\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4320 all=36914 active=1906 piece=▁가짐에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4340 all=36897 active=1889 piece=▁궁금할\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4360 all=36883 active=1875 piece=▁더러워\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4380 all=36878 active=1870 piece=▁망했어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4400 all=36862 active=1854 piece=▁부딪혔\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4420 all=36851 active=1830 piece=▁실수할\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4440 all=36837 active=1816 piece=▁없지만\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4460 all=36830 active=1809 piece=▁재회를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4480 all=36827 active=1806 piece=▁치과에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4500 all=36814 active=1793 piece=▁힘들고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4520 all=36818 active=1845 piece=▁나을지도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4540 all=36807 active=1834 piece=▁사랑하기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4560 all=36797 active=1824 piece=▁연락해서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4580 all=36785 active=1812 piece=▁차분하게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4600 all=36778 active=1805 piece=▁되었나봐요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4620 all=36760 active=1821 piece=▁아이스크림\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4640 all=36744 active=1805 piece=▁걱정되겠네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4660 all=36738 active=1799 piece=▁떡\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4680 all=36767 active=1828 piece=▁팀\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4700 all=36813 active=1874 piece=두절\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4720 all=36855 active=1880 piece=셨나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4740 all=36922 active=1947 piece=의금\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4760 all=36968 active=1993 piece=힌다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4780 all=36977 active=2002 piece=▁구속\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4800 all=36992 active=2017 piece=▁내내\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4820 all=36990 active=1848 piece=▁떨쳐\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4840 all=36995 active=1853 piece=▁미용\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4860 all=37001 active=1859 piece=▁불금\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4880 all=37016 active=1874 piece=▁숨막\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4900 all=37029 active=1887 piece=▁염탐\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4920 all=37053 active=1874 piece=▁잘자\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4940 all=37064 active=1885 piece=▁참석\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4960 all=37083 active=1904 piece=▁한계\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4980 all=37122 active=1943 piece=생인데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5000 all=37173 active=1994 piece=▁가까운\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5020 all=37168 active=1854 piece=▁기억의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5040 all=37164 active=1850 piece=▁드리고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5060 all=37152 active=1838 piece=▁맞춤법\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5080 all=37144 active=1830 piece=▁바빠서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5100 all=37138 active=1824 piece=▁상처도\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5120 all=37124 active=1843 piece=▁않는게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5140 all=37117 active=1836 piece=▁유난히\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5160 all=37106 active=1825 piece=▁지나가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5180 all=37099 active=1818 piece=▁편하고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5200 all=37085 active=1804 piece=▁혼자인\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5220 all=37104 active=1873 piece=▁관리하는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5240 all=37088 active=1857 piece=▁맞추세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5260 all=37071 active=1840 piece=▁생일이네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5280 all=37060 active=1829 piece=▁연락두절\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5300 all=37046 active=1815 piece=▁잊혀지지\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5320 all=37032 active=1839 piece=▁카톡으로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5340 all=37024 active=1831 piece=▁결혼하는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5360 all=37005 active=1812 piece=▁��간이네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5380 all=36989 active=1796 piece=▁힘든가봐요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5400 all=36981 active=1788 piece=▁굳\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5420 all=37002 active=1869 piece=▁엇\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5440 all=37023 active=1890 piece=가의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5460 all=37059 active=1926 piece=네여\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5480 all=37096 active=1963 piece=린라\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5500 all=37128 active=1995 piece=서와\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5520 all=37162 active=1889 piece=오래\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5540 all=37207 active=1934 piece=질제\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5560 all=37244 active=1971 piece=향을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5580 all=37245 active=1972 piece=▁골프\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5600 all=37249 active=1976 piece=▁나나\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5620 all=37247 active=1861 piece=▁늙어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5640 all=37245 active=1859 piece=▁때요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5660 all=37243 active=1857 piece=▁목적\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5680 all=37252 active=1866 piece=▁반장\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5700 all=37272 active=1886 piece=▁브랜\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5720 all=37288 active=1878 piece=▁손편\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5740 all=37303 active=1893 piece=▁알까\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5760 all=37309 active=1899 piece=▁오셨\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5780 all=37309 active=1899 piece=▁이왕\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5800 all=37327 active=1917 piece=▁전학\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5820 all=37338 active=1877 piece=▁지적\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5840 all=37349 active=1888 piece=▁친절\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5860 all=37354 active=1893 piece=▁폭식\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5880 all=37364 active=1903 piece=▁회의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5900 all=37384 active=1923 piece=센터에\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5920 all=37422 active=1908 piece=해졌죠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5940 all=37434 active=1920 piece=▁갈수록\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5960 all=37417 active=1903 piece=▁괜찮길\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5980 all=37404 active=1890 piece=▁꼼수를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6000 all=37392 active=1878 piece=▁다르게\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6020 all=37378 active=1856 piece=▁되었을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6040 all=37369 active=1847 piece=▁만났던\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6060 all=37359 active=1837 piece=▁멈추지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6080 all=37345 active=1823 piece=▁버리는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6100 all=37336 active=1814 piece=▁비밀은\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6120 all=37319 active=1850 piece=▁성공한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6140 all=37314 active=1845 piece=▁싶으면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6160 all=37299 active=1830 piece=▁안좋아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6180 all=37292 active=1823 piece=▁어플을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6200 all=37276 active=1807 piece=▁오해가\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6220 all=37269 active=1857 piece=▁이별��\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6240 all=37257 active=1845 piece=▁잊지못\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6260 all=37254 active=1842 piece=▁조심히\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6280 all=37237 active=1825 piece=▁지진시\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6300 all=37222 active=1810 piece=▁파도가\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6320 all=37204 active=1844 piece=▁헤아릴\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6340 all=37203 active=1843 piece=성이에요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6360 all=37218 active=1858 piece=▁갑작스럽\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6380 all=37209 active=1849 piece=▁금수저로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6400 all=37193 active=1833 piece=▁놀이공���\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6420 all=37174 active=1841 piece=▁마셨는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6440 all=37156 active=1823 piece=▁반가워요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6460 all=37144 active=1811 piece=▁사랑인지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6480 all=37127 active=1794 piece=▁시간내서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6500 all=37112 active=1779 piece=▁어둠에서\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6520 all=37094 active=1838 piece=▁외로움을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6540 all=37080 active=1824 piece=▁인생에서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6560 all=37066 active=1810 piece=▁좋아지는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6580 all=37049 active=1793 piece=▁표현하지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6600 all=37031 active=1775 piece=▁헷갈리네\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6620 all=37024 active=1845 piece=▁고백하는게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6640 all=37006 active=1827 piece=▁덜어보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6660 all=36986 active=1807 piece=▁비하하지는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6680 all=36968 active=1789 piece=▁스트레스를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6700 all=36948 active=1769 piece=▁운동하세요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6720 all=36932 active=1832 piece=��졸업하는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6740 all=36914 active=1814 piece=▁행복하세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6760 all=36894 active=1794 piece=▁사랑하는지는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6780 all=36874 active=1774 piece=▁말씀드려보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6800 all=36876 active=1776 piece=▁눕\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6820 all=36893 active=1859 piece=▁엿\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6840 all=36904 active=1870 piece=▁헥\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6860 all=36922 active=1888 piece=구로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6880 all=36952 active=1918 piece=년반\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6900 all=36972 active=1938 piece=두리\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: chatbot.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: chatbot.vocab\n"
     ]
    }
   ],
   "source": [
    "corpus = \"all.txt\"\n",
    "prefix = \"chatbot\"\n",
    "vocab_size = 8000\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_file = \"chatbot.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "START_TOKEN = [2]\n",
    "END_TOKEN = [3]\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    zeros1 = np.zeros(MAX_LENGTH, dtype=int)\n",
    "    zeros2 = np.zeros(MAX_LENGTH, dtype=int)\n",
    "    sentence1 = START_TOKEN + vocab.encode_as_ids(sentence1) + END_TOKEN\n",
    "    zeros1[:len(sentence1)] = sentence1[:MAX_LENGTH]\n",
    "\n",
    "    sentence2 = START_TOKEN + vocab.encode_as_ids(sentence2) + END_TOKEN\n",
    "    zeros2[:len(sentence2)] = sentence2[:MAX_LENGTH]\n",
    "\n",
    "    tokenized_inputs.append(zeros1)\n",
    "    tokenized_outputs.append(zeros2)\n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_encode, answers_encode = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2 5567 6968 3211  111    3    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[   2 5194  217 5936    7    3    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(questions_encode[0])\n",
    "print(answers_encode[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Transformer\n",
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "\n",
    "class TFModel(nn.Module):\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TFModel, self).__init__()\n",
    "        self.transformer = Transformer(ninp, nhead, dim_feedforward=nhid, num_encoder_layers=nlayers, num_decoder_layers=nlayers,dropout=dropout)\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "\n",
    "        self.pos_encoder_d = PositionalEncoding(ninp, dropout)\n",
    "        self.encoder_d = nn.Embedding(ntoken, ninp)\n",
    "\n",
    "        self.ninp = ninp\n",
    "        self.ntoken = ntoken\n",
    "\n",
    "        self.linear = nn.Linear(ninp, ntoken)\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, tgt, srcmask, tgtmask, srcpadmask, tgtpadmask):\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        tgt = self.encoder_d(tgt) * math.sqrt(self.ninp)\n",
    "        tgt = self.pos_encoder_d(tgt)\n",
    "\n",
    "\n",
    "        output = self.transformer(src.transpose(0,1), tgt.transpose(0,1), srcmask, tgtmask, src_key_padding_mask=srcpadmask, tgt_key_padding_mask=tgtpadmask)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "def gen_attention_mask(x):\n",
    "    mask = torch.eq(x, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, questions, answers):\n",
    "        questions = np.array(questions)\n",
    "        answers = np.array(answers)\n",
    "        self.inputs = questions\n",
    "        self.dec_inputs = answers[:,:-1]\n",
    "        self.outputs = answers[:,1:]\n",
    "        self.length = len(questions)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return (self.inputs[idx], self.dec_inputs[idx], self.outputs[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "dataset = SequenceDataset(questions_encode, answers_encode)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "lr = 1e-4\n",
    "model = TFModel(vocab_size+7, 256, 8, 512, 2, 0.1).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab size = vocab size + 7(tokens)  \n",
    "lr = 1e-4  \n",
    "d_emb model = 256  \n",
    "num heads = 8  \n",
    "dff = 512  \n",
    "num_layer = 2  \n",
    "dropout = 0.1  \n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/185 [00:00<?, ?it/s]/opt/conda/lib/python3.12/site-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "1.200: 100%|██████████| 185/185 [00:08<00:00, 20.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | loss: 1.7367147909628378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.948: 100%|██████████| 185/185 [00:08<00:00, 21.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | loss: 1.0689259297138936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.929: 100%|██████████| 185/185 [00:08<00:00, 20.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | loss: 1.0205562282252956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.003: 100%|██████████| 185/185 [00:08<00:00, 20.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | loss: 0.9933618493982264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.960: 100%|██████████| 185/185 [00:08<00:00, 21.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | loss: 0.9707379315350507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.096: 100%|██████████| 185/185 [00:08<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | loss: 0.9515060837204392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.938: 100%|██████████| 185/185 [00:08<00:00, 21.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | loss: 0.9328920931429476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.919: 100%|██████████| 185/185 [00:08<00:00, 21.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | loss: 0.9126381539009712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.850: 100%|██████████| 185/185 [00:08<00:00, 21.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | loss: 0.8923018171980575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.828: 100%|██████████| 185/185 [00:08<00:00, 21.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 | loss: 0.8717954068570524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.769: 100%|██████████| 185/185 [00:08<00:00, 21.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 | loss: 0.8507085851720861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.814: 100%|██████████| 185/185 [00:08<00:00, 21.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 | loss: 0.8297703098606419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.824: 100%|██████████| 185/185 [00:08<00:00, 21.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 | loss: 0.8083848283097551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.844: 100%|██████████| 185/185 [00:08<00:00, 21.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 | loss: 0.7873042751002957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.739: 100%|██████████| 185/185 [00:08<00:00, 21.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 | loss: 0.7656348151129645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.700: 100%|██████████| 185/185 [00:08<00:00, 21.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 | loss: 0.7435122103304477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.687: 100%|██████████| 185/185 [00:08<00:00, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 | loss: 0.7216505720808699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.648: 100%|██████████| 185/185 [00:08<00:00, 21.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 | loss: 0.7001219053526182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.665: 100%|██████████| 185/185 [00:08<00:00, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 | loss: 0.6776258726377745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.654: 100%|██████████| 185/185 [00:08<00:00, 21.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 | loss: 0.6546461363096495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.634: 100%|██████████| 185/185 [00:08<00:00, 21.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 | loss: 0.6317866557353252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.559: 100%|██████████| 185/185 [00:08<00:00, 21.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 | loss: 0.6084829794394003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.595: 100%|██████████| 185/185 [00:08<00:00, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 | loss: 0.5852791863518793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.472: 100%|██████████| 185/185 [00:08<00:00, 21.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 | loss: 0.562544786607897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.633: 100%|██████████| 185/185 [00:08<00:00, 21.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 | loss: 0.5408105798669763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.563: 100%|██████████| 185/185 [00:08<00:00, 21.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 | loss: 0.5184783523147171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.513: 100%|██████████| 185/185 [00:08<00:00, 21.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 | loss: 0.49597704088365707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.409: 100%|██████████| 185/185 [00:08<00:00, 21.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 | loss: 0.4735247225374789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.461: 100%|██████████| 185/185 [00:08<00:00, 21.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 | loss: 0.4525422379777238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.439: 100%|██████████| 185/185 [00:08<00:00, 21.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 | loss: 0.43134448077227616\n"
     ]
    }
   ],
   "source": [
    "epoch = 30\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.train()\n",
    "for i in range(epoch):\n",
    "    batchloss = 0.0\n",
    "    progress = tqdm(dataloader)\n",
    "    for (inputs, dec_inputs, outputs) in progress:\n",
    "        optimizer.zero_grad()\n",
    "        src_mask = model.generate_square_subsequent_mask(MAX_LENGTH).to(device)\n",
    "        src_padding_mask = gen_attention_mask(inputs).to(device)\n",
    "        tgt_mask = model.generate_square_subsequent_mask(MAX_LENGTH-1).to(device)\n",
    "        tgt_padding_mask = gen_attention_mask(dec_inputs).to(device)\n",
    "\n",
    "        result = model(inputs.to(device), dec_inputs.to(device), src_mask, tgt_mask, src_padding_mask,tgt_padding_mask)\n",
    "        loss = criterion(result.permute(1,2,0), outputs.to(device).long())\n",
    "        progress.set_description(\"{:0.3f}\".format(loss))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batchloss += loss\n",
    "    print(\"epoch:\",i+1,\"|\",\"loss:\",batchloss.cpu().item() / len(dataloader))"
   ]
  },
  {
   "attachments": {
    "cce8ffa9-e4f5-4c0e-b2b0-1868e3a3bf3b.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:cce8ffa9-e4f5-4c0e-b2b0-1868e3a3bf3b.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"chatbot.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "def evaluate(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    input = torch.tensor([START_TOKEN + vocab.encode_as_ids(sentence) + END_TOKEN]).to(device)\n",
    "    output = torch.tensor([START_TOKEN]).to(device)\n",
    "\n",
    "    # 디코더의 예측 시작\n",
    "    model.eval()\n",
    "    for i in range(MAX_LENGTH):\n",
    "        src_mask = model.generate_square_subsequent_mask(input.shape[1]).to(device)\n",
    "        tgt_mask = model.generate_square_subsequent_mask(output.shape[1]).to(device)\n",
    "\n",
    "        src_padding_mask = gen_attention_mask(input).to(device)\n",
    "        tgt_padding_mask = gen_attention_mask(output).to(device)\n",
    "\n",
    "        predictions = model(input, output, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask).transpose(0,1)\n",
    "        # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = torch.LongTensor(torch.argmax(predictions.cpu(), axis=-1))\n",
    "\n",
    "\n",
    "        # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "        if torch.equal(predicted_id[0][0], torch.tensor(END_TOKEN[0])):\n",
    "            break\n",
    "\n",
    "        # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "        # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "        output = torch.cat([output, predicted_id.to(device)], axis=1)\n",
    "\n",
    "    return torch.squeeze(output, axis=0).cpu().numpy()\n",
    "\n",
    "def predict(sentence):\n",
    "    prediction = evaluate(sentence)\n",
    "    predicted_sentence = vocab.Decode(list(map(int,[i for i in prediction if i < vocab_size+7])))\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 난 뭘 해야 할까?\n",
      "Output: 좋아하는 건 없어요 .\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"chatbot.pth\"))\n",
    "result = predict(\"난 뭘 해야 할까?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "증강X, 전처리는 기본으로 한 베이스라인 모델을 구현했다. loss값은 잘 내려갔지만 결과값이 만족스럽지 못하다. 이제 과적합을 방지하기 위해 데이터 증강, validation set 분리, 하이퍼 파라미터 튜닝을 진행하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim==4.3.3 in /opt/conda/lib/python3.12/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /opt/conda/lib/python3.12/site-packages (from gensim==4.3.3) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from gensim==4.3.3) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.12/site-packages (from gensim==4.3.3) (7.3.1)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim==4.3.3) (1.17.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim==4.3.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Word2Vec bin 파일 경로\n",
    "bin_file_path = \"ko_c.bin\"\n",
    "\n",
    "wv = KeyedVectors.load_word2vec_format(bin_file_path, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. Lexical Substitution 을 구현해봅시다.\n",
    "def lexical_sub(sentence, wv):\n",
    "    # 문장을 토큰화\n",
    "    tokens = sentence.split()\n",
    "\n",
    "    # 유효한 단어 필터링 (임베딩에 존재하는 단어만 고려)\n",
    "    valid_tokens = [tok for tok in tokens if tok in wv]\n",
    "\n",
    "    # 대체할 단어 선택 (임베딩 내 존재하는 단어 중 하나)\n",
    "    if not valid_tokens:\n",
    "        return sentence  # 모든 단어가 임베딩 내에 없으면 원래 문장 반환\n",
    "\n",
    "    selected_tok = random.choice(valid_tokens)\n",
    "\n",
    "    # 가장 유사한 단어 찾기\n",
    "    similar_word = wv.most_similar(selected_tok)[0][0]\n",
    "\n",
    "    # 변환된 문장 생성\n",
    "    new_sentence = \" \".join([similar_word if tok == selected_tok else tok for tok in tokens])\n",
    "\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11823/11823 [00:19<00:00, 607.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 끗 !', '12시 땡 !', '1지망 학교의 떨어졌어', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 놀러가고 싶다', '3박4일 만큼 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네', 'PPL 심하네']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "new_corpus = []\n",
    "\n",
    "for old_src in tqdm(questions):\n",
    "    new_src = lexical_sub(old_src, wv)\n",
    "    if new_src is not None:\n",
    "        new_corpus.append(new_src)\n",
    "    # Augmentation이 없더라도 원본 문장을 포함시킵니다\n",
    "    new_corpus.append(old_src)\n",
    "\n",
    "print(new_corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11823/11823 [00:25<00:00, 466.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['하루가 각기 가네요 .', '하루가 또 가네요 .', '위로해 드립니다 는데', '위로해 드립니다 .', '여행은 항상 좋죠 .', '여행은 언제나 좋죠 .', '여행은 항상 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 는데', '눈살이 찌푸려지죠 .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "new_corpus = []\n",
    "\n",
    "for old_src in tqdm(answers):\n",
    "    new_src = lexical_sub(old_src, wv)\n",
    "    if new_src is not None:\n",
    "        new_corpus.append(new_src)\n",
    "    # Augmentation이 없더라도 원본 문장을 포함시킵니다\n",
    "    new_corpus.append(old_src)\n",
    "\n",
    "print(new_corpus[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 쓰이지 않는 문장들이지만, 형태적으로는 몰라도 의미적으로는 옳은 문장이므로 그대로 진행한다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "lr = 1e-4\n",
    "model = TFModel(vocab_size+7, 256, 8, 512, 2, 0.1).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 30\n",
    "\n",
    "model.train()\n",
    "for i in range(epoch):\n",
    "    batchloss = 0.0\n",
    "    progress = tqdm(dataloader)\n",
    "    for (inputs, dec_inputs, outputs) in progress:\n",
    "        optimizer.zero_grad()\n",
    "        src_mask = model.generate_square_subsequent_mask(MAX_LENGTH).to(device)\n",
    "        src_padding_mask = gen_attention_mask(inputs).to(device)\n",
    "        tgt_mask = model.generate_square_subsequent_mask(MAX_LENGTH-1).to(device)\n",
    "        tgt_padding_mask = gen_attention_mask(dec_inputs).to(device)\n",
    "\n",
    "        result = model(inputs.to(device), dec_inputs.to(device), src_mask, tgt_mask, src_padding_mask,tgt_padding_mask)\n",
    "        loss = criterion(result.permute(1,2,0), outputs.to(device).long())\n",
    "        progress.set_description(\"{:0.3f}\".format(loss))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batchloss += loss\n",
    "    print(\"epoch:\",i+1,\"|\",\"loss:\",batchloss.cpu().item() / len(dataloader))"
   ]
  },
  {
   "attachments": {
    "6624fdaf-5a1e-4eba-9c29-4dc3dead5a31.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:6624fdaf-5a1e-4eba-9c29-4dc3dead5a31.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"chatbot_withDataAug.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 난 뭘 해야 할까?\n",
      "Output: 좋아하는 건 없어요 .\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"chatbot.pth\"))\n",
    "result = predict(\"난 뭘 해야 할까?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과적합을 확인하기 위해 val set을 추가하여 그래프를 보고 과적합을 확인하겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# 전체 데이터셋 (예: train_dataset)\n",
    "total_size = len(dataset)\n",
    "val_size = int(total_size * 0.2)   # 20%를 validation\n",
    "train_size = total_size - val_size\n",
    "\n",
    "dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   2, 1752, 4994,    3,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0]), array([   2,  561, 3900,  936, 7026,  526,    7,    3,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0]), array([ 561, 3900,  936, 7026,  526,    7,    3,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0]))\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3개는 각각 inputseq, targetseq, decoderseq으로 볼 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 증강강도를 고정하고 다른 하이퍼 파라미터를 그리드 서치로 최적값을 찾아보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1421\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1395\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1463\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1664\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.2101\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.9573\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1472\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1418\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1467\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1887\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.5644\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.4143\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 8.1554\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1378\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1459\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1838\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.3689\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.1142\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 7.3593\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1442\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1499\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.2394\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.9937\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.8450\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 8.0524\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 7.6258\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 8.0492\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.2427\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.6012\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.4020\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 7.6970\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 7.7786\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 5.8692\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.7172\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 2.5935\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 3.5102\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1391\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1371\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1429\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1575\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.0873\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.7902\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1441\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1414\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1456\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1754\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.4078\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.2053\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1438\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1382\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1425\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1654\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.1627\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.8530\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1564\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1440\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1470\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.2133\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.6951\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.4932\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 7.8667\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 7.9481\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 5.8526\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.2222\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.3158\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.0168\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 7.2445\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 7.1777\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 7.2794\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 6.4180\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 2.1161\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.9509\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1378\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1335\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1405\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1450\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 0.9390\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.6047\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1409\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1380\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1434\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1647\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.2246\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.9327\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 7.6621\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1355\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1382\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1478\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 0.9499\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.5740\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 4.2054\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1456\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1464\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1839\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.4054\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.1093\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 8.2683\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 7.4919\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 8.0330\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 7.1910\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.0359\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.6719\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 7.5071\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 7.9107\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 7.4693\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.3264\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.6602\n",
      "실행 중: {'d_model': 256, 'num_heads': 4, 'dff': 2048, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.4245\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1413\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1403\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1454\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1645\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.2431\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.0362\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1497\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1426\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1518\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1882\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.6142\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.4616\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1446\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1404\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1449\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1811\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.4018\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.1764\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1545\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1463\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1523\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.2437\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 2.0570\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.9100\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 8.1897\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 7.6929\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 7.5580\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.2288\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.6742\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.4747\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 7.7889\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 8.2886\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 7.6211\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 8.0440\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 2.6568\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 3.5725\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1385\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1361\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1443\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1585\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.1053\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.8295\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1491\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1414\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1443\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1841\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.4434\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.2163\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1442\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1383\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1430\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1672\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.2026\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.8974\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1553\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 5.9880\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1441\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.2159\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.7422\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.5291\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 8.2673\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 7.9145\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 6.3749\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.2528\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.3528\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.1076\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 8.0147\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 8.2084\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 5.6265\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 7.2103\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 2.1749\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 1024, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 3.0026\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1381\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1344\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1419\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1490\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 0.9628\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.6126\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1426\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1388\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1437\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1647\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.2535\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.9639\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1400\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1376\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1395\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1502\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 0.9659\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.6031\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 8.2211\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1421\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1424\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1878\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.4247\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.1502\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 8.3027\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 8.8068\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 7.5960\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1752\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.0639\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.7195\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 8.1767\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 7.7361\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 8.0989\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 7.2405\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.7227\n",
      "실행 중: {'d_model': 256, 'num_heads': 8, 'dff': 2048, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.4710\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1345\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1319\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1387\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1364\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 0.4171\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 0.8306\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1433\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1357\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1462\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1432\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 0.5953\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.1619\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 7.8378\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 6.3817\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1385\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1360\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 0.4966\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 0.9656\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 6.4265\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 7.1698\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1501\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1428\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 0.8731\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.5559\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 7.7462\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 7.9432\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 7.8393\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 7.6669\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 0.6324\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.1885\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 7.0696\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 7.3515\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 7.4390\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 7.9731\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 1.3743\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 512, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 2.1835\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1349\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1294\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1369\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1340\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 0.3747\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 0.7412\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 0.1436\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 0.1374\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1427\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1383\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 0.5400\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.0501\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 6.3865\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 6.3878\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1378\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1389\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 0.4296\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 0.8290\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 7.0737\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 6.7408\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 0.1495\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 0.1404\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 0.7857\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 4, 'dropout': 0.2, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.3973\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
      "Validation Loss: 7.7945\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128}\n",
      "Validation Loss: 6.4775\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
      "Validation Loss: 7.9696\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 128}\n",
      "Validation Loss: 7.7550\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 64}\n",
      "Validation Loss: 0.5390\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.1, 'lr': 0.0001, 'batch_size': 128}\n",
      "Validation Loss: 1.0097\n",
      "실행 중: {'d_model': 512, 'num_heads': 4, 'dff': 1024, 'num_layers': 6, 'dropout': 0.2, 'lr': 0.001, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === 하이퍼파라미터 후보 ===\n",
    "param_grid = {\n",
    "    \"d_model\": [256, 512],\n",
    "    \"num_heads\": [4, 8],\n",
    "    \"dff\": [512, 1024, 2048],\n",
    "    \"num_layers\": [2, 4, 6],\n",
    "    \"dropout\": [0.1, 0.2],\n",
    "    \"lr\": [1e-3, 5e-4, 1e-4],\n",
    "    \"batch_size\": [64, 128]\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# === 마스크 생성 함수 ===\n",
    "def create_masks(src, tgt, model):\n",
    "    src_pad_mask = (src == 0)\n",
    "    tgt_pad_mask = (tgt == 0)\n",
    "    tgt_mask = model.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
    "    src_mask = None\n",
    "    return src_mask, tgt_mask, src_pad_mask, tgt_pad_mask\n",
    "\n",
    "# === Grid Search ===\n",
    "for combo in itertools.product(*param_grid.values()):\n",
    "    params = dict(zip(param_grid.keys(), combo))\n",
    "    print(f\"실행 중: {params}\")\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=params[\"batch_size\"])\n",
    "\n",
    "    model = TFModel(\n",
    "        vocab_size + 7,\n",
    "        params[\"d_model\"],\n",
    "        params[\"num_heads\"],\n",
    "        params[\"dff\"],\n",
    "        params[\"num_layers\"],\n",
    "        params[\"dropout\"]\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "\n",
    "    # === 학습 ===\n",
    "    for epoch in range(10):#10개로 실시\n",
    "        model.train()\n",
    "        for input_seq, target_seq, decoder_input in train_loader:\n",
    "            input_seq = input_seq.to(device)\n",
    "            target_seq = target_seq.to(device)\n",
    "            decoder_input = decoder_input.to(device)\n",
    "\n",
    "            # 시퀀스 길이 맞추기 (batch 마지막에서 mismatch 방지)\n",
    "            min_len = min(decoder_input.size(1), target_seq.size(1)-1)\n",
    "            decoder_input = decoder_input[:, :min_len]\n",
    "            target_seq_cut = target_seq[:, 1:][:, :min_len]\n",
    "\n",
    "            src_mask, tgt_mask, src_pad_mask, tgt_pad_mask = create_masks(input_seq, decoder_input, model)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(\n",
    "                input_seq,\n",
    "                decoder_input,\n",
    "                src_mask,\n",
    "                tgt_mask,\n",
    "                src_pad_mask,\n",
    "                tgt_pad_mask\n",
    "            )\n",
    "\n",
    "            # outputs: (seq_len, batch, vocab) → (batch, seq_len, vocab)\n",
    "            outputs = outputs.transpose(0,1)\n",
    "\n",
    "            loss = criterion(\n",
    "                outputs.reshape(-1, outputs.size(-1)),\n",
    "                target_seq_cut.reshape(-1)\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # === 검증 ===\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for input_seq, target_seq, decoder_input in val_loader:\n",
    "            input_seq = input_seq.to(device)\n",
    "            target_seq = target_seq.to(device)\n",
    "            decoder_input = decoder_input.to(device)\n",
    "\n",
    "            min_len = min(decoder_input.size(1), target_seq.size(1)-1)\n",
    "            decoder_input = decoder_input[:, :min_len]\n",
    "            target_seq_cut = target_seq[:, 1:][:, :min_len]\n",
    "\n",
    "            src_mask, tgt_mask, src_pad_mask, tgt_pad_mask = create_masks(input_seq, decoder_input, model)\n",
    "\n",
    "            outputs = model(\n",
    "                input_seq,\n",
    "                decoder_input,\n",
    "                src_mask,\n",
    "                tgt_mask,\n",
    "                src_pad_mask,\n",
    "                tgt_pad_mask\n",
    "            )\n",
    "            outputs = outputs.transpose(0,1)\n",
    "\n",
    "            loss = criterion(\n",
    "                outputs.reshape(-1, outputs.size(-1)),\n",
    "                target_seq_cut.reshape(-1)\n",
    "            )\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    results.append((params, val_loss))\n",
    "\n",
    "# === 최적 하이퍼파라미터 ===\n",
    "best_params, best_loss = min(results, key=lambda x: x[1])\n",
    "print(\"\\n최적 하이퍼파라미터:\", best_params)\n",
    "print(\"Validation Loss:\", best_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "맨 처음에 진행했을때에는     \n",
    "    \"d_model\": [128, 256, 512],  \n",
    "    \"num_heads\": [4, 8],  \n",
    "    \"dff\": [512, 1024, 2048],  \n",
    "    \"num_layers\": [2, 4, 6],  \n",
    "    \"dropout\": [0.1, 0.2, 0.3],  \n",
    "    \"lr\": [1e-3, 5e-4, 1e-4],  \n",
    "    \"batch_size\": [32, 64, 128]  \n",
    "으로 진행 하려 했으나, 머신 성능을 고려하지 않고 진행하여 1000여번의 계산을 하다가는 문제가 생길 거 같아 줄여서 진행하였다. 중간중간 버그가 많이 일어나 그 점을 아래에 정리해 두었다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ValueError: too many values to unpack (expected 2)\n",
    "원인: DataLoader에서 튜플 (x, y, z) 형태의 데이터가 나오는데, 학습 루프에서 for x, y in train_loader:처럼 2개만 받으려 했기 때문.\n",
    "해결: for input_seq, target_seq, decoder_input in train_loader:로 수정해서 3개를 받도록 변경.\n",
    "\n",
    "2. TFModel.forward() missing 4 required positional arguments\n",
    "원인: TFModel.forward()가 srcmask, tgtmask, srcpadmask, tgtpadmask를 반드시 받도록 정의되어 있음.\n",
    "그런데 학습 루프에서 단순히 model(x, y)만 호출하여 마스크 인자를 전달하지 않았음.\n",
    "해결: forward 호출 전에 마스크를 생성해서 함께 전달하도록 수정.\n",
    "srcmask → 보통 None 사용\n",
    "tgtmask → 미래 토큰 차단용 (causal mask)\n",
    "srcpadmask, tgtpadmask → 패딩 토큰 무시용 마스크\n",
    "\n",
    "3. ValueError: Expected input batch_size (1248) to match target batch_size (1216)\n",
    "원인: outputs와 target의 시퀀스 길이가 다름.\n",
    "outputs는 (seq_len, batch, vocab)\n",
    "target은 [:, 1:]로 잘라 쓰는데 길이가 outputs와 안 맞을 수 있음 (특히 마지막 배치).\n",
    "해결: 학습 루프에서 두 시퀀스 길이를 min_len = min(outputs_len, target_len)으로 맞춰 잘라냄.\n",
    "decoder_input과 target_seq[:, 1:] 모두 min_len에 맞게 컷팅해서 loss 계산.\n",
    "\n",
    "4. 출력 차원 문제\n",
    "원인: PyTorch nn.Transformer 출력 차원은 (seq_len, batch, vocab)인데, CrossEntropyLoss는 (batch, seq_len, vocab)을 기대함.\n",
    "해결: outputs = outputs.transpose(0,1)으로 차원을 맞춘 후 loss 계산.\n",
    "\n",
    "5. 최종 정리된 학습 구조\n",
    "데이터 로딩 → (input_seq, target_seq, decoder_input)\n",
    "마스크 생성 (srcmask, tgtmask, srcpadmask, tgtpadmask)\n",
    "모델 forward 호출 시 마스크 전달\n",
    "출력 차원 변환 (seq_len, batch, vocab) → (batch, seq_len, vocab)\n",
    "target 시퀀스와 길이 맞춤 후 loss 계산\n",
    "역전파 및 최적화\n",
    "즉, 오류들은 대부분\n",
    "데이터 unpack 문제\n",
    "forward() 인자 누락\n",
    "출력/정답 시퀀스 길이 불일치\n",
    "출력 차원 불일치\n",
    "에서 발생했고, 각각 올바르게 인자 전달, 길이 맞춤, 차원 변환으로 해결되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 아직 추가 실험을 진행하고 싶다. 각 모델들에게 '공정한 기준' 을 적용한다면 lr이 작은 경우에는 더 많은 에포크를 돌려주어야 그 모델의 최대 퍼포먼스를 볼 수 있다고 생각한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(hypotheses, list_of_references, max_n=4):\n",
    "\n",
    "    assert len(hypotheses) == len(list_of_references)\n",
    "\n",
    "    scores = []\n",
    "    for hyp, refs in zip(hypotheses, list_of_references):\n",
    "        score = bleu_score(hyp, refs, max_n=max_n)\n",
    "        scores.append(score)\n",
    "\n",
    "    corpus_bleu = sum(scores) / len(scores)\n",
    "    return corpus_bleu, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_bleu, scores = calculate_bleu(hypotheses, list_of_references)\n",
    "print(\"Corpus BLEU:\", corpus_bleu)\n",
    "print(\"Sentence BLEUs:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "849767edceeeddf53965c2c22dc0d6f4cc62af5f2af22e684245cca2d0b8102d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
